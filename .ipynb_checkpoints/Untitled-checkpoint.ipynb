{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821dae86-5ba2-4363-ac7d-c27d9260bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.models import load_model\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc27491-dfbb-4da6-98ff-e88cc360b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = './data/'\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "frames = {}\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    df_name = os.path.splitext(csv_file)[0]  # Use file name as DataFrame name (without extension)\n",
    "    df = pd.read_csv(file_path)\n",
    "    frames[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a76c6b-1ed4-49a6-8b39-16ec37c5727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, frame in frames.items():\n",
    "    translation_table = str.maketrans('', '', string.digits)\n",
    "    sitename = title.split(\"_\")[0].translate(translation_table)\n",
    "    frame['Site'] = sitename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0c9469-cb52-4d56-963b-2ce0f9e7fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(input_string):\n",
    "    if type(input_string) == float:\n",
    "        return input_string\n",
    "    if 'Application Data' in input_string:\n",
    "        return 'Application Data'\n",
    "    if 'Payload' in input_string:\n",
    "        return 'Payload'\n",
    "    if 'Handshake' in input_string:\n",
    "        return 'Handshake'\n",
    "    translation_table = str.maketrans('', '', '0123456789')\n",
    "    return input_string.translate(translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e6a659-c4e6-4e6f-acf2-fa4c260e240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_dic_map(input_string):\n",
    "    return info_dic[input_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f768d721-048d-44c3-a307-69d9964ff156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_target(df):\n",
    "    if df['Site'].iloc[0] == ('amazon' or 'chatgpt' or 'bing' or 'discord' or 'googledrive' or 'wmregistration' or 'quizlet'):\n",
    "        df['Target'] = 'sud'\n",
    "        return df\n",
    "    elif df['Site'].iloc[0] == ('discordstream' or 'fortnite' or 'minecraft'):\n",
    "        df['Target'] = 'cud'\n",
    "        return df\n",
    "    elif df['Site'].iloc[0] == ('youtube' or 'hulu'):\n",
    "        df['Target'] = 'cd'\n",
    "        return df\n",
    "    else:\n",
    "        df['Target'] = 'sd'\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d1f0c6-e66f-4533-849f-f3103b8595e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(text):\n",
    "    if type(text) == (float or Int):\n",
    "        return text\n",
    "    # Use regex pattern to find values enclosed within square brackets\n",
    "    pattern = r'\\[([^\\]]+)\\]'  # Matches anything inside square brackets\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return text\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d1d541-082c-4e1a-bf93-abb26436fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.159.130.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.165.77.79\n",
      "142.251.167.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.25.11.55\n",
      "239.255.255.250\n",
      "162.254.199.181\n",
      "172.253.63.188\n",
      "192.168.0.255\n",
      "162.159.135.234\n",
      "8.8.4.4\n",
      "23.38.126.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.159.130.234\n",
      "162.159.128.233\n",
      "162.159.130.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.48.104.110\n",
      "142.251.167.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.159.130.234\n",
      "162.159.130.232\n",
      "162.159.128.233\n",
      "162.159.135.233\n",
      "31.25.11.18\n",
      "162.159.130.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.251.167.100\n",
      "3.129.219.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
      "/var/folders/87/1q7dsfgn0hv13r545hhmys_c0000gn/T/ipykernel_50382/3407542501.py:111: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n"
     ]
    }
   ],
   "source": [
    "site_dic = {}\n",
    "info_dic = {}\n",
    "j = 0\n",
    "for title, frame in frames.items():\n",
    "    frame['Time Delta'] = frame['Time'].diff().fillna(0)\n",
    "    #1 = user\n",
    "    #0 = site\n",
    "    \n",
    "    frame['Source'] = frame['Source'].str.replace('18.160.17.214', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('18.160.17.214', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('172.66.40.147', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('172.66.40.147', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('104.234.169.167', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('104.234.169.167', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('162.159.128.232', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('162.159.128.232', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('100.69.171.196', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('100.69.171.196', '1')\n",
    "    frame['Source'] = frame['Source'].str.replace('169.254.243.145', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('169.254.243.145', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('192.168.0.92', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('192.168.0.92', '1')\n",
    "    frame['Source'] = frame['Source'].str.replace('192.168.0.129', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('192.168.0.129', '1')\n",
    "    '169.254.243.145'\n",
    "    \n",
    "\n",
    "    #amazon\n",
    "    frame['Source'] = frame['Source'].str.replace('204.79.197.200', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('204.79.197.200', '0')\n",
    "\n",
    "    #chatgpt\n",
    "    frame['Source'] = frame['Source'].str.replace('104.18.37.228', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('104.18.37.228', '0')\n",
    "\n",
    "    #discord / discordstream\n",
    "    frame['Source'] = frame['Source'].str.replace('66.22.231.191', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('66.22.231.191', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('66.22.196.159', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('66.22.196.159', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('35.214.213.22', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('35.214.213.22', '0')\n",
    "\n",
    "    frame['Source'] = frame['Source'].str.replace('23.48.104.108', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('23.48.104.108', '0')\n",
    "\n",
    "    \n",
    "\n",
    "    #wmreg\n",
    "    frame['Source'] = frame['Source'].str.replace('3.14.34.81', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('3.14.34.81', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('100.86.171.196', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('100.86.171.196', '1')\n",
    "\n",
    "    #fortnite\n",
    "    frame['Source'] = frame['Source'].str.replace('3.144.65.185', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('3.144.65.185', '0')\n",
    "\n",
    "    #googledrive\n",
    "    frame['Source'] = frame['Source'].str.replace('172.253.122.139', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('172.253.122.139', '0')\n",
    "\n",
    "    #minecraft\n",
    "    frame['Source'] = frame['Source'].str.replace('209.222.115.47', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('209.222.115.47', '0')\n",
    "\n",
    "    #quizlet\n",
    "    frame['Source'] = frame['Source'].str.replace('104.16.133.27', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('104.16.133.27', '0')\n",
    "\n",
    "    #hulu\n",
    "    frame['Source'] = frame['Source'].str.replace('23.48.104.112', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('23.48.104.112', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('192.168.0.104', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('192.168.0.104', '1')\n",
    "    \n",
    "    frame['Source'] = frame['Source'].str.replace('20.36.181.22', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('20.36.181.22', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('192.168.0.200', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('192.168.0.200', '1')\n",
    "\n",
    "    #ryrod / ugm / wpbegin\n",
    "    frame['Source'] = frame['Source'].str.replace('100.86.7.137', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('100.86.7.137', '1')\n",
    "    frame['Source'] = frame['Source'].str.replace('104.18.10.41', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('104.18.10.41', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('172.66.43.109', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('172.66.43.109', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('13.84.36.2', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('13.84.36.2', '0')\n",
    "    frame['Source'] = frame['Source'].str.replace('208.80.154.224', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('208.80.154.224', '0')\n",
    "\n",
    "    #youtube\n",
    "    frame['Source'] = frame['Source'].str.replace('2600:8805:3e22:4100:68dd:8e31:1a2:1f62', '1')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('2600:8805:3e22:4100:68dd:8e31:1a2:1f62', '1')\n",
    "    frame['Source'] = frame['Source'].str.replace('2607:f8b0:4004:f::a', '0')\n",
    "    frame['Destination'] = frame['Destination'].str.replace('2607:f8b0:4004:f::a', '0')\n",
    "\n",
    "    frame['Info'] = frame['Info'].apply(extract_values)\n",
    "\n",
    "    for i in frame['Destination'].unique():\n",
    "        if (i != '1' and i!='0'):\n",
    "            print(i)\n",
    "            frame['Source'] = frame['Source'].str.replace(i, '0')\n",
    "            frame['Destination'] = frame['Destination'].str.replace(i, '0')\n",
    "\n",
    "    frame = apply_target(frame)\n",
    "\n",
    "    protocol_map = {'UDP':0, 'TCP':1, 'TLSv1.2':2, 'TLSv1.3':3, 'RTCP': 4, 'QUIC': 5, 'SSDP':6, 'R-GOOSE':7}\n",
    "    frame['Protocol'] = frame['Protocol'].replace(protocol_map)\n",
    "    \n",
    "    translation_table = str.maketrans('', '', string.digits)\n",
    "    sitename = title.split(\"_\")[0].translate(translation_table)\n",
    "    frame['Info'] = frame['Info'].apply(remove_numbers)\n",
    "    for value in frame['Info'].unique():\n",
    "        if value not in info_dic:\n",
    "            j+=1\n",
    "            info_dic[value] = j\n",
    "\n",
    "    frame['Info'] = frame['Info'].apply(info_dic_map)\n",
    "    \n",
    "    if sitename not in site_dic:\n",
    "        site_dic[sitename] = 0\n",
    "    rows_per = 50\n",
    "    total_dataframes = (len(frame)) // rows_per\n",
    "    for i in range(total_dataframes):\n",
    "        site_dic[sitename] += 1\n",
    "        file_path = './data2/' + sitename + '_' + str(\"{:03d}\".format(site_dic[sitename]) + '.csv')\n",
    "        start_index = i * rows_per\n",
    "        end_index = (i + 1) * rows_per\n",
    "        smaller_df = frame.iloc[start_index:end_index]\n",
    "        smaller_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a5e24-e939-4926-8d7a-3f6d90917218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92bfc4bb-db1b-4659-806a-a333b2cd029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'  >   Len=': 1, 'Application Data': 2, 'ACK': 3, 'TCP Previous segment not captured': 4, 'PSH, ACK': 5, 'TCP Dup ACK #': 6, 'TCP Out-Of-Order': 7, 'TCP Spurious Retransmission': 8, 'TCP Fast Retransmission': 9, 'TCP Retransmission': 10, 'Payload': 11, 'TCP Window Update': 12, 'Initial, DCID=cdacf, PKN: , PADDING, CRYPTO, PING, PADDING, CRYPTO, PADDING, CRYPTO, PING, PING, PING, CRYPTO, PING, CRYPTO, PING, PADDING, CRYPTO, PING, PING, CRYPTO, CRYPTO, PADDING, CRYPTO, CRYPTO': 13, '-RTT, DCID=cdacf': 14, 'Initial, SCID=dffdfdefddbbaddcdc, PKN: , ACK': 15, 'Handshake': 16, 'ACK, CWR': 17, 'Initial, DCID=acc, PKN: , CRYPTO, PADDING, CRYPTO, PADDING, PING, CRYPTO, CRYPTO, CRYPTO, PADDING': 18, '-RTT, DCID=acc': 19, 'Initial, SCID=afbdaaddc, PKN: , ACK': 20, 'Ignored Unknown Record': 21, 'Receiver Report   ': 22, 'Sender Report   Unknown   ': 23, 'SYN': 24, 'SYN, ACK': 25, 'Client Hello (SNI=en.wikipedia.org)': 26, 'Initial, DCID=eabedfdcc, PKN: , PADDING, CRYPTO, CRYPTO, PADDING, CRYPTO, PADDING, CRYPTO, PADDING, PING, CRYPTO, PADDING, CRYPTO, CRYPTO, PADDING, CRYPTO': 27, '-RTT, DCID=eabedfdcc': 28, 'Initial, SCID=abbdacfaebdfaa, PKN: , ACK': 29, 'Encrypted Heartbeat, Ignored Unknown Record': 30, 'Sender Report   ': 31, 'Initial, DCID=aeef, PKN: , PING, PADDING, CRYPTO, CRYPTO, CRYPTO, PADDING, CRYPTO, CRYPTO, PADDING, CRYPTO, CRYPTO, PADDING, CRYPTO, CRYPTO, CRYPTO': 32, 'Initial, SCID=ccbceabcdcabdb, PKN: , ACK': 33, 'Initial, SCID=ccbceabcdcabdb, PKN: , CRYPTO': 34, 'M-SEARCH * HTTP/. ': 35, 'FIN, ACK': 36, 'Client Hello (SNI=i.scdn.co)': 37, nan: 38, 'Malformed Packet': 39, 'Client Hello': 40, 'TCP Keep-Alive': 41, 'TCP Keep-Alive ACK': 42, 'Client Hello (SNI=cdn.discordapp.com)': 43, 'Server Hello, Change Cipher Spec': 44, 'TCP ZeroWindow': 45, 'Initial, DCID=daccaae, PKN: , CRYPTO, PADDING, PING, PADDING, PING, PADDING, PING, PING, PING, PING, PING, PADDING': 46}\n"
     ]
    }
   ],
   "source": [
    "print(info_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c38b52-01ff-4c64-a55f-552c4187900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDP = 0\n",
    "# TCP = 1\n",
    "# TLSv1.2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e65052d-22f1-4e90-aeef-15fc062ea4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "rows_per = 50\n",
    "total_dataframes = (len(df) + rows_per - 1) // rows_per\n",
    "smaller_dfs = []\n",
    "for i in range(total_dataframes):\n",
    "    start_index = i * rows_per\n",
    "    end_index = (i + 1) * rows_per\n",
    "    smaller_df = df.iloc[start_index:end_index]\n",
    "    smaller_dfs.append(smaller_df)\n",
    "    print(end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5dbff4-afd7-4513-b4ed-41c80aaeee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = {'amazon':28, 'bing':110, 'chatgpt':26, 'discord':100, 'googledrive':20, 'discordstream':20, 'fortnite':30, 'minecraft': 63, 'ryrod':75, 'ugm': 42, 'wpbeginner': 20, 'Wikipedia':17, 'youtube': 38, 'hulu':45, 'quizlet':30, 'wmregistration':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137a8518-8468-4a16-8329-f1e294f24a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {\"sd\":0, \"sud\":1, \"cd\":2, \"cud\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b62cffd8-78f0-4d13-aee2-dc7a0acd8c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved to: ./data3/x_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = './data2/'\n",
    "\n",
    "# List to store all dataframes from CSV files\n",
    "all_dataframes = []\n",
    "test_dfs = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "i = 0\n",
    "y_train = pd.DataFrame(columns=['Series', 'Target'])\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Sample'] = i\n",
    "        y_train = y_train._append({'Series': i, 'Target': target_map[df.iloc[0]['Target']]}, ignore_index=True)\n",
    "        i+=1\n",
    "        # Append the dataframe to the list\n",
    "        all_dataframes.append(df)\n",
    "            \n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Path to the new combined CSV file\n",
    "output_csv_path = './data3/x_train.csv'\n",
    "\n",
    "# Write the combined dataframe to a new CSV file\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "y_train.to_csv('./data3/y_train.csv', index=False)\n",
    "\n",
    "print(f\"Combined CSV file saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d815281c-f7ec-447e-972e-bfe818492791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (rnn): LSTM(6, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel (nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"FORWARD\")\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t for t in (h0, c0)]\n",
    "\n",
    "input_size = 6  # Number of features in input sequence\n",
    "hidden_size = 64  # Number of features in LSTM hidden state\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "output_size = 4  # Number of output units (for regression tasks)\n",
    "\n",
    "model5 = LSTMClassifier(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "print(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e0d5d7-7f30-40a1-a8cc-40a82e35ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model5.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d91a9b2d-3eb2-4cff-b2b3-bb4e83737346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0fc5d6-f86e-41d0-8c4d-ccceb6cf65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2_path = './data2/'\n",
    "# data2_files = [file for file in os.listdir(data2_path) if file.endswith('.csv')]\n",
    "# datasets = []\n",
    "# for file in data2_files:\n",
    "#     file_path = os.path.join(data2_path, file)\n",
    "#     df = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Example: Assuming 'features' and 'target' are columns in the CSV\n",
    "#     features = df.drop('Time', axis=1)  # Extract features (input data)\n",
    "#     features = features.drop('Site', axis=1)  # Extract features (input data)\n",
    "#     features = features.drop('No.', axis=1)  # Extract features (input data)\n",
    "#     features = np.array(features.iloc[:,:-1].values)\n",
    "#     target = df['Target'].values  # Extract target values\n",
    "#     print(target)\n",
    "    \n",
    "#     # Convert to PyTorch tensors\n",
    "#     features_tensor_list = [torch.tensor(arr, dtype=torch.float32) for arr in features]\n",
    "#     target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "    \n",
    "#     # Create a TensorDataset for the CSV data\n",
    "#     dataset = TensorDataset(features_tensor, target_tensor)\n",
    "#     datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95600091-5b8c-45b1-8bc4-2465e9930d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('./data3/x_train.csv')\n",
    "y_train = pd.read_csv('./data3/y_train.csv')\n",
    "x_train['Source'] = x_train['Source'].astype(int)\n",
    "x_train['Destination'] = x_train['Destination'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7c0154-8455-4ddb-b0d0-bfe1e32953ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39450 entries, 0 to 39449\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   No.          39450 non-null  int64  \n",
      " 1   Time         39450 non-null  float64\n",
      " 2   Source       39450 non-null  int64  \n",
      " 3   Destination  39450 non-null  int64  \n",
      " 4   Protocol     39450 non-null  int64  \n",
      " 5   Length       39450 non-null  int64  \n",
      " 6   Info         39450 non-null  int64  \n",
      " 7   Site         39450 non-null  object \n",
      " 8   Time Delta   39450 non-null  float64\n",
      " 9   Target       39450 non-null  object \n",
      " 10  Sample       39450 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 3.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x_train['Site'].unique()\n",
    "print(x_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46ef66ae-ffdc-46e9-9f53-347e060423e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Source', 'Destination', 'Protocol', 'Length', 'Info', 'Time Delta']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_COLUMNS = ['Source', 'Destination', 'Protocol', 'Length', 'Info', 'Time Delta']\n",
    "FEATURE_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f63c10e-64ee-4683-a8e0-419decad4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for sample, group in x_train.groupby('Sample'):\n",
    "    sequence_features = group[FEATURE_COLUMNS]\n",
    "    \n",
    "    label = y_train[y_train.Series == sample].iloc[0].Target\n",
    "    print(label)\n",
    "    \n",
    "    sequences.append((sequence_features, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d2d679-6f33-47cf-8c0c-a4c067391b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(    Source  Destination  Protocol  Length  Info    Time Delta\n",
      "50       0            1         1    1514     3  0.000000e+00\n",
      "51       0            1         2    1268     2  1.000000e-06\n",
      "52       0            1         1    1514     3  1.000000e-06\n",
      "53       0            1         1    1514     3  1.000000e-06\n",
      "54       0            1         2    1268     2  0.000000e+00\n",
      "55       0            1         1    1514     3  1.000000e-06\n",
      "56       0            1         2     803     2  1.000000e-06\n",
      "57       0            1         2      92     2  0.000000e+00\n",
      "58       1            0         1      54     3  1.530000e-04\n",
      "59       0            1         1      56     3  1.035000e-02\n",
      "60       0            1         2     687     2  2.955300e-02\n",
      "61       1            0         1      54     3  9.240000e-04\n",
      "62       0            1         2     620     2  8.500000e-05\n",
      "63       0            1         2      92     2  1.000000e-06\n",
      "64       1            0         1      54     3  6.100000e-05\n",
      "65       1            0         1    1494     3  3.312100e-02\n",
      "66       1            0         1    1494     3  2.000000e-06\n",
      "67       1            0         2     357     2  2.600000e-05\n",
      "68       1            0         1    1494     3  3.308000e-03\n",
      "69       1            0         1    1494     3  1.000000e-06\n",
      "70       1            0         2     357     2  2.200000e-05\n",
      "71       0            1         1      56     3  8.926000e-03\n",
      "72       0            1         2     990     2  3.142000e-03\n",
      "73       0            1         2      92     2  2.000000e-06\n",
      "74       0            1         1      56     3  0.000000e+00\n",
      "75       0            1         1      56     3  1.000000e-06\n",
      "76       1            0         1      54     3  1.350000e-04\n",
      "77       0            1         2     742     2  4.458000e-03\n",
      "78       0            1         2      92     2  1.000000e-06\n",
      "79       1            0         1      54     3  1.080000e-04\n",
      "80       1            0         1    1494     3  4.914700e-02\n",
      "81       1            0         1    1494     3  2.000000e-06\n",
      "82       1            0         2     499     2  2.600000e-05\n",
      "83       1            0         2     290     2  1.960000e-04\n",
      "84       0            1         1      56     3  1.294900e-02\n",
      "85       0            1         1      56     3  1.000000e-06\n",
      "86       0            1         1    1514     3  1.515720e-01\n",
      "87       0            1         2     916     2  3.363000e-03\n",
      "88       0            1         2      92     2  1.000000e-06\n",
      "89       1            0         1      54     3  1.090000e-04\n",
      "90       1            0         1    1494     3  7.597700e-02\n",
      "91       1            0         1    1494     3  2.000000e-06\n",
      "92       1            0         2     479     2  2.100000e-05\n",
      "93       1            0         1    1494     3  3.313000e-03\n",
      "94       1            0         1    1494     3  2.000000e-06\n",
      "95       1            0         2     566     2  1.600000e-05\n",
      "96       1            0         1    1494     3  3.504000e-03\n",
      "97       1            0         1    1494     3  2.000000e-06\n",
      "98       1            0         2     557     2  2.300000e-05\n",
      "99       1            0         1    1494    10  2.822100e-02, 0)\n"
     ]
    }
   ],
   "source": [
    "print(sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90792937-e793-4de2-b264-5624a929e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, test_sequences = train_test_split(sequences,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2531eb38-5268-473b-908f-cd0f83f0c25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(631, 158)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences), len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12272b13-4fb4-498d-bc50-11358acc29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50, 6])\n"
     ]
    }
   ],
   "source": [
    "for seq, label in test_sequences:\n",
    "    print(torch.Tensor(seq.to_numpy()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc5aacf5-14ef-48c6-a75b-439054308093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurfacePredictor(\n",
      "  (model): SequenceModel(\n",
      "    (lstm): LSTMModel(\n",
      "      (lstm): LSTM(6, 256, num_layers=3, batch_first=True)\n",
      "      (fc): Linear(in_features=256, out_features=4, bias=True)\n",
      "    )\n",
      "    (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/andretran/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | SequenceModel    | 1.3 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.300     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andretran/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': tensor([[[0.0000e+00, 1.0000e+00, 1.0000e+00, 1.5140e+03, 3.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 2.0000e+00, 1.0570e+03, 2.0000e+00,\n",
      "          1.0000e-06],\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00, 5.4000e+01, 3.0000e+00,\n",
      "          6.4000e-05],\n",
      "         ...,\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00, 5.4000e+01, 1.2000e+01,\n",
      "          5.5000e-05],\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.4940e+03, 3.0000e+00,\n",
      "          2.4410e-03],\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00, 1.4940e+03, 3.0000e+00,\n",
      "          7.0000e-06]],\n",
      "\n",
      "        [[0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          1.0000e-06],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          1.0000e-06],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          1.0000e-06],\n",
      "         [1.0000e+00, 0.0000e+00, 5.0000e+00, 9.5000e+01, 1.1000e+01,\n",
      "          2.8700e-04],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          4.4840e-03]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 1.0000e+00, 5.4000e+01, 3.0000e+00,\n",
      "          3.3000e-05],\n",
      "         [1.0000e+00, 0.0000e+00, 2.0000e+00, 1.8320e+03, 2.0000e+00,\n",
      "          5.1719e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 5.6000e+01, 3.0000e+00,\n",
      "          4.5801e-02],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 2.9254e+04, 4.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 2.0000e+00, 8.7800e+02, 2.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 2.0000e+00, 2.6334e+04, 2.0000e+00,\n",
      "          0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 1.0000e+00, 0.0000e+00, 2.1100e+02, 1.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 0.0000e+00, 6.1000e+02, 1.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 0.0000e+00, 6.3700e+02, 1.0000e+00,\n",
      "          0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.2420e+03, 1.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 0.0000e+00, 2.4600e+02, 1.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 0.0000e+00, 1.2420e+03, 1.0000e+00,\n",
      "          0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 0.0000e+00, 1.0000e+00, 7.8000e+01, 2.4000e+01,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 7.4000e+01, 2.5000e+01,\n",
      "          2.5742e-02],\n",
      "         [1.0000e+00, 0.0000e+00, 1.0000e+00, 6.6000e+01, 3.0000e+00,\n",
      "          1.1900e-04],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 1.5140e+03, 3.0000e+00,\n",
      "          1.0000e-06],\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 1.5140e+03, 5.0000e+00,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 1.0000e+00, 1.5140e+03, 3.0000e+00,\n",
      "          1.0000e-06]],\n",
      "\n",
      "        [[0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          1.0000e-06],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          1.0000e-06],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          0.0000e+00],\n",
      "         [0.0000e+00, 1.0000e+00, 5.0000e+00, 1.2920e+03, 1.1000e+01,\n",
      "          0.0000e+00]]]), 'labels': tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])}\n",
      "torch.Size([16, 50, 6])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SequenceModel.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 141\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m    140\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[0;32m--> 141\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, data_module)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m val_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39mstep_args)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[27], line 106\u001b[0m, in \u001b[0;36mSurfacePredictor.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    104\u001b[0m sequences \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    105\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 106\u001b[0m loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(sequences, labels)\n\u001b[1;32m    108\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    109\u001b[0m step_accuracy \u001b[38;5;241m=\u001b[39m accuracy(predictions, labels)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 84\u001b[0m, in \u001b[0;36mSurfacePredictor.forward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 84\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel()\n\u001b[1;32m     85\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     86\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: SequenceModel.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "class SurfaceDataset(Dataset):\n",
    "\n",
    "  def __init__(self,sequences):\n",
    "      self.sequences = sequences\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sequences)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    sequence, label = self.sequences[idx]\n",
    "    return dict(\n",
    "        sequence = torch.Tensor(sequence.to_numpy()),\n",
    "        labels = torch.as_tensor(label)\n",
    "    )\n",
    "\n",
    "class SurfaceDataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_sequences, test_sequences, batch_size=8):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_sequences = train_sequences\n",
    "    self.test_sequences = test_sequences\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = SurfaceDataset(self.train_sequences)\n",
    "    self.test_dataset = SurfaceDataset(self.test_sequences)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=0\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=False,\n",
    "      num_workers=0\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=False,\n",
    "      num_workers=0\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "class SequenceModel(nn.Module):\n",
    "  def __init__(self,n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "    super().__init__()\n",
    "    self.lstm = LSTMModel(input_size = n_features, hidden_size=n_hidden, num_layers = n_layers, output_size = 4)\n",
    "    #   nn.LSTM(\n",
    "    #     input_size=n_features,\n",
    "    #     hidden_size=n_hidden,\n",
    "    #     num_layers=n_layers,\n",
    "    #     batch_first=True,\n",
    "    #     dropout=0.75\n",
    "    # )\n",
    "\n",
    "    self.classifier = nn.Linear(n_hidden,n_classes)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # self.lstm.flatten_parameters()\n",
    "    _,(hidden,_) = self.lstm(x)\n",
    "\n",
    "    out = hidden[-1]\n",
    "    return self.classifier(out)\n",
    "\n",
    "class SurfacePredictor(pl.LightningModule):\n",
    "\n",
    "  def __init__(self,n_features:int, n_classes: int):\n",
    "    super().__init__()\n",
    "    self.model = SequenceModel(n_features, n_classes)\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x, labels=None):\n",
    "    print(x.shape)\n",
    "    output = self.model()\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels)\n",
    "    return loss, output\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(sequences, labels)\n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "    \n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    print(batch)\n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(sequences, labels)\n",
    "      \n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    \n",
    "    sequences = batch[\"sequence\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(sequences, labels)\n",
    "    predictions = torch.argmax(outputs,dim=1)\n",
    "    step_accuracy = accuracy(predictions, labels)\n",
    "\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return optim.Adam(self.parameters(), lr=0.0001)\n",
    "N_EPOCHS = 250\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "data_module = SurfaceDataModule(\n",
    "  train_sequences,\n",
    "  test_sequences,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "model = SurfacePredictor(n_features=6,n_classes=4)\n",
    "print(model)\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9e93cd0-fa33-436b-b77c-7f56630c6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (rnn): LSTM(6, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = LSTMClassifier(6, 64, 2, 4)\n",
    "print(model2)\n",
    "x = torch.randn(10, 50, 6)\n",
    "# output = model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e87f3-7455-4a94-981a-dfef384b6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
